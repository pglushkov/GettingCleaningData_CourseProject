main plan:

1) read all feature-names from 'features.txt' - this our map of columns
2) - read actual data from 'train' and 'test' sets by read.table() from 'X_train.txt' and 'Y_train.txt'
   - read actual labeling of activities from y_train.txt and y_test.txt
   - read actual subject-labeling of data from subject_train.txt and subject_test.txt
     
3) rbind these subsets
4) add additional merged columns to final data-sets
5) select only mean/std columns by using 'columns-map' from (1)
    5.1) make some renamings ... this is an arguable one ...
6) create new data-set as written in task : 
    From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each
    subject
7) save created data-set as written in task : 
    Please upload the tidy data set created in step 5 of the instructions. Please upload your data set as a txt file created with write.table()
    using row.name=FALSE (do not cut and paste a dataset directly into the text box, as this may cause errors saving your submission).
    
8) Create a README.md file with description of the script "You should also include a README.md in the repo with your scripts."
   It explains how " ... all of the scripts work and how they are connected"
9) Create CodeBook.md with "a code book that describes the variables, the data, and any transformations or work that you performed to clean
   up the data"